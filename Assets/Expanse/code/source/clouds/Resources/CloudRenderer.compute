#pragma only_renderers d3d11 ps4 xboxone vulkan metal switch

#pragma kernel FULLSCREEN main=FULLSCREEN
#pragma kernel REPROJECT main=REPROJECT
#pragma kernel SHADOWMAP main=SHADOWMAP
#pragma kernel REFLECTION main=REFLECTION
#pragma kernel GAMEPLAY main=GAMEPLAY

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariablesFunctions.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Sky/SkyUtils.hlsl"

/* Expanse globals */
#include "../../directLight/planet/PlanetGlobals.hlsl"
#include "../../main/QualityGlobals.hlsl"
#include "../../lighting/LightingGlobals.hlsl"
#include "../CloudGlobals.hlsl"

#include "../../common/Mapping.hlsl"
#include "../../common/Random.hlsl"
#include "../../common/Geometry.hlsl"
#include "../../celestialBodies/CelestialBodyDatatypes.cs.hlsl"
#include "../../atmosphere/AtmosphereMapping.hlsl"
#include "../../atmosphere/AtmosphereGeometry.hlsl"
#include "../../atmosphere/Atmosphere.hlsl"
#include "../../atmosphere/AtmosphereRenderer.cs.hlsl"
#include "../CloudDatatypes.cs.hlsl"
#include "../CloudGeometry.hlsl"
#include "../Clouds.hlsl"
#include "../../main/GameplayQueries.cs.hlsl"

/* Outputs. */
RW_TEXTURE2D_ARRAY(float4, _LightingFramebuffers);
RW_TEXTURE2D_ARRAY(float4, _TransmittanceHitFramebuffers);
RW_TEXTURE2D_ARRAY(float4, _GBuffer);
RW_TEXTURE2D_ARRAY(float, _ReflectionT);

/* Layer to render. */
int _layerIndex;

/* Resolution + camera params. */
float4 _framebufferResolution;
float4 _subresolution;
float4 _WorldSpaceCameraPos1;
int _frameCount;

/* Previous buffers + camera data for reprojection. */
TEXTURE2D_ARRAY(_PrevLightingFramebuffers);
TEXTURE2D_ARRAY(_PrevTransmittanceHitFramebuffers);
TEXTURE2D(_CameraMotionVectorsTexture_Copy);
float4x4 _previousViewMatrix;
float4x4 _previousProjectionMatrix;

/* For reflection probes. */
float4 _reflectionProbeResolution;
int _reflectionProbeReprojectionFrames;
int _reflectionProbeDenoisingFrames;

/* For shadow maps specifically. */
RW_TEXTURE2D_ARRAY(float4, _ShadowMapFramebuffers);
float4 _shadowMapResolution;
int _shadowLightIndex;
int _shadowLayerIndex;

/* For gameplay queries specificially. */
RWStructuredBuffer<QueryInfo> _GameplayQueryBuffer;
int _numGameplayQueries;

[numthreads(8, 8, 1)]
void FULLSCREEN(uint3 id : SV_DispatchThreadID) {
  UniversalCloudLayerRenderSettings layerSettings = _ExpanseCloudLayers[_layerIndex];
  PlanetRenderSettings planet = _ExpansePlanetRenderSettings[0];

  uint2 subPixel = Clouds::getCurrentSubpixel(_frameCount, layerSettings.reprojectionFrames);
  uint2 pixel = id.xy * layerSettings.reprojectionFrames + subPixel;

  /* If density is zero, write a null result. */
  if (layerSettings.density == 0) {
    _LightingFramebuffers[uint3(pixel, _layerIndex)] = float4(0, 0, 0, -1);
    _TransmittanceHitFramebuffers[uint3(pixel, _layerIndex)] = float4(1, 1, 1, -1);
    return;
  }

  /* Convert clipspace coordinate to worldspace direction. */
  float3 d = -GetSkyViewDirWS((pixel + 0.5) / _subresolution.xy);
  /* Convert camera origin to planet space. */
  float3 o = Mapping::transformPointToPlanetSpace(_WorldSpaceCameraPos1.xyz,
    planet.originOffset, planet.radius);

  /* Get the depth. */
  float2 depthUV = (pixel + 0.5) / _framebufferResolution.xy;
  float linearDepth = Linear01Depth(SampleCameraDepth(depthUV), _ZBufferParams) * _ProjectionParams.z;
  /* Make sure depth is distance to view aligned plane. */
  float3 viewDir = -GetSkyViewDirWS((_framebufferResolution.xy * 0.5 + 0.5) / _subresolution.xy);
  float cosTheta = dot(viewDir, d);
  float depth = linearDepth / max(cosTheta, 0.00001);
  float farClip = _ProjectionParams.z / max(cosTheta, 0.00001);
  /* Set depth to -1 if it's at the far clip, since this means there was no
   * geo hit. */
  depth = depth < farClip - 0.001 ? depth : -1;

  /* Sample ambient light probe. */
  const int kAmbientLightSamples = 3;
  float3 ambient = 0;
  for (int i = 0; i < kAmbientLightSamples; i++) {
    float3 fibonacciDir = Utilities::fibonacciHemisphere(i, kAmbientLightSamples);
    float muFibonacci = dot(normalize(o), fibonacciDir);
    SkyIntersectionData intersectionFibonacci = AtmosphereGeometry::traceSkyVolume(o, fibonacciDir,
      planet.radius, planet.atmosphereRadius);
    float tFibonacci = intersectionFibonacci.endT - intersectionFibonacci.startT;
    float theta = AtmosphereMapping::d_to_theta(fibonacciDir, o);
    float2 atmoUV = AtmosphereMapping::mapSkyRenderCoordinate(length(o), muFibonacci,
      theta, planet.atmosphereRadius, planet.radius, tFibonacci,
      intersectionFibonacci.groundHit, 64, 64); // HACK: 64's here are a guess at the sky texture res... but it doesn't matter since we're taking such a low frequency estimate.
    float4 atmosphere = SAMPLE_TEXTURE2D_LOD(_SkyViewTex, s_linear_clamp_sampler, atmoUV, 0);
    // [HACK]: to avoid the sky ambient contribution getting too blue, desaturate it!
    const float3 desaturate = 0.5;
    float3 grayscale = Utilities::average(atmosphere.xyz);
    ambient += lerp(atmosphere.xyz, grayscale, desaturate);
  }
  ambient /= float(kAmbientLightSamples);

  /* Create the right kind of geometry and render! */
  CloudResult result;
  switch (layerSettings.geometryType) {
    case CLOUDGEOMETRYTYPE_PLANE: {
      CloudPlane geometry = CloudPlane::CreateCloudPlane(layerSettings.geometryXExtent,
        layerSettings.geometryZExtent, layerSettings.geometryHeight, layerSettings.apparentThickness, planet.radius);
      result = Clouds::renderClouds2D(layerSettings, geometry, o, d, ambient);
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_PLANE: {
      CloudCurvedPlane geometry = CloudCurvedPlane::CreateCloudCurvedPlane(layerSettings.geometryXExtent,
        layerSettings.geometryZExtent, layerSettings.geometryHeight, layerSettings.apparentThickness, planet.radius);
      result = Clouds::renderClouds2D(layerSettings, geometry, o, d, ambient);
      break;
    }
    case CLOUDGEOMETRYTYPE_BOX_VOLUME: {
      float blueNoise = Random::random_3_1(float3(depthUV, (uint(_frameCount) % 256) / 256.0));
      CloudBoxVolume geometry = CloudBoxVolume::CreateCloudBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      result = Clouds::renderClouds3D(layerSettings, geometry, o, d, depth, blueNoise, ambient, _frameCount);
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_BOX_VOLUME: {
      float blueNoise = Random::random_3_1(float3(depthUV, (uint(_frameCount) % 256) / 256.0));
      CloudCurvedBoxVolume geometry = CloudCurvedBoxVolume::CreateCloudCurvedBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      result = Clouds::renderClouds3D(layerSettings, geometry, o, d, depth, blueNoise, ambient, _frameCount);
      break;
    }
    default: {
      result.lighting = 0;
      result.transmittance = 1;
      result.t = -1;
      result.geoHit = -1;
      break;
    }
  }

  _LightingFramebuffers[uint3(pixel, _layerIndex)] = float4(result.lighting, depth);
  _TransmittanceHitFramebuffers[uint3(pixel, _layerIndex)] = float4(result.transmittance, result.t);
}

/* Returns intersection with cloud geometry for storing in the gbuffer. */
float2 RenderGBuffer(float3 d, UniversalCloudLayerRenderSettings layerSettings) {
  PlanetRenderSettings planet = _ExpansePlanetRenderSettings[0];

  /* Convert camera origin to planet space. */
  float3 o = Mapping::transformPointToPlanetSpace(_WorldSpaceCameraPos1.xyz,
    planet.originOffset, planet.radius);

  /* Compute planet intersection to test against. */
  float3 planetIntersections = Geometry::intersectSphere(o, d, planet.radius);
  float planetIntersection = Utilities::minNonNegative(planetIntersections.x, planetIntersections.y);
  planetIntersection = planetIntersection < 0 ? FLT_MAX : planetIntersection;

  float2 intersection = float2(-1, -1);
  switch (layerSettings.geometryType) {
    case CLOUDGEOMETRYTYPE_PLANE: {
      CloudPlane geometry = CloudPlane::CreateCloudPlane(layerSettings.geometryXExtent,
        layerSettings.geometryZExtent, layerSettings.geometryHeight, layerSettings.apparentThickness, planet.radius);
      intersection.x = geometry.intersect(o, d).x;
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_PLANE: {
      CloudCurvedPlane geometry = CloudCurvedPlane::CreateCloudCurvedPlane(layerSettings.geometryXExtent,
        layerSettings.geometryZExtent, layerSettings.geometryHeight, layerSettings.apparentThickness, planet.radius);
      intersection.x = geometry.intersect(o, d).x;
      break;
    }
    case CLOUDGEOMETRYTYPE_BOX_VOLUME: {
      CloudBoxVolume geometry = CloudBoxVolume::CreateCloudBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      intersection.xy = geometry.intersect(o, d);
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_BOX_VOLUME: {
      CloudCurvedBoxVolume geometry = CloudCurvedBoxVolume::CreateCloudCurvedBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      intersection.xy = geometry.intersect(o, d);
      break;
    }
    default: {
      intersection = float2(-1, -1);
      break;
    }
  }

  if (planetIntersection < intersection.x) {
    intersection.xy = float2(-1, -1);
  }

  return Clouds::mapGBuffer(intersection);
}

/* This is the best way to decide whether to accept or reject a
 * reprojected sample. Refer to unreal engine's docs on their TAA
 * implementation---just search "neighborhood clamping". */
void neighborhoodClamp(uint layer, uint neighborhoodRange, 
  float3 transmittance, float3 lighting, uint2 id,
  out float3 clampedTransmittance, out float3 clampedLighting) {
  // Neighborhood clamping.
  float3 lMiddle = _LightingFramebuffers[uint3(id, layer)].xyz;
  float3 lLeft = _LightingFramebuffers[uint3(min(max(0, id - uint2(neighborhoodRange, 0)), _framebufferResolution.xy), layer)].xyz;
  float3 lRight = _LightingFramebuffers[uint3(min(max(0, id + uint2(neighborhoodRange, 0)), _framebufferResolution.xy), layer)].xyz;  
  float3 lBottom = _LightingFramebuffers[uint3(min(max(0, id - uint2(0, neighborhoodRange)), _framebufferResolution.xy), layer)].xyz;
  float3 lTop = _LightingFramebuffers[uint3(min(max(0, id + uint2(0, neighborhoodRange)), _framebufferResolution.xy), layer)].xyz;
  float3 lMin = min(min(min(lMiddle, lLeft), min(lRight, lBottom)), lTop);
  float3 lMax = max(max(max(lMiddle, lLeft), max(lRight, lBottom)), lTop);
  clampedLighting = max(lMin, min(lighting, lMax));

  float3 tMiddle = _TransmittanceHitFramebuffers[uint3(id, layer)].xyz;
  float3 tLeft = _TransmittanceHitFramebuffers[uint3(min(max(0, id - uint2(neighborhoodRange, 0)), _framebufferResolution.xy), layer)].xyz;
  float3 tRight = _TransmittanceHitFramebuffers[uint3(min(max(0, id + uint2(neighborhoodRange, 0)), _framebufferResolution.xy), layer)].xyz;  
  float3 tBottom = _TransmittanceHitFramebuffers[uint3(min(max(0, id - uint2(0, neighborhoodRange)), _framebufferResolution.xy), layer)].xyz;
  float3 tTop = _TransmittanceHitFramebuffers[uint3(min(max(0, id + uint2(0, neighborhoodRange)), _framebufferResolution.xy), layer)].xyz;
  float3 tMin = min(min(min(tMiddle, tLeft), min(tRight, tBottom)), tTop);
  float3 tMax = max(max(max(tMiddle, tLeft), max(tRight, tBottom)), tTop);
  clampedTransmittance = max(tMin, min(transmittance, tMax));
}

void neighborhoodClampWithDepthRejection(uint layer, uint neighborhoodRange, 
  float3 transmittance, float3 lighting, uint2 id, float depth,
  out float3 clampedTransmittance, out float3 clampedLighting) {

  uint2 idLeft = min(max(0, id - uint2(neighborhoodRange, 0)), _framebufferResolution.xy);
  uint2 idRight = min(max(0, id + uint2(neighborhoodRange, 0)), _framebufferResolution.xy);
  uint2 idBottom = min(max(0, id - uint2(0, neighborhoodRange)), _framebufferResolution.xy);
  uint2 idTop = min(max(0, id + uint2(0, neighborhoodRange)), _framebufferResolution.xy);

  // Neighborhood clamping.
  const uint kNumSamples = 5;
  float4 lMiddle = _LightingFramebuffers[uint3(id, layer)];
  float4 lLeft = _LightingFramebuffers[uint3(idLeft, layer)];
  float4 lRight = _LightingFramebuffers[uint3(idRight, layer)];  
  float4 lBottom = _LightingFramebuffers[uint3(idBottom, layer)];
  float4 lTop = _LightingFramebuffers[uint3(idTop, layer)];
  float4 l[kNumSamples] = {lMiddle, lLeft, lRight, lBottom, lTop};

  float4 tMiddle = _TransmittanceHitFramebuffers[uint3(id, layer)];
  float4 tLeft = _TransmittanceHitFramebuffers[uint3(idLeft, layer)];
  float4 tRight = _TransmittanceHitFramebuffers[uint3(idRight, layer)];  
  float4 tBottom = _TransmittanceHitFramebuffers[uint3(idBottom, layer)];
  float4 tTop = _TransmittanceHitFramebuffers[uint3(idTop, layer)];
  float4 t[kNumSamples] = {tMiddle, tLeft, tRight, tBottom, tTop};

  float3 lMin = FLT_MAX;
  float3 lMax = 0;
  float3 tMin = 1;
  float3 tMax = 0;
  bool anySuccess = false;
  float kTolerance = FLT_MAX;
  [unroll(kNumSamples)]
  for (uint i = 0; i < kNumSamples; i++) {
    if (sign(depth) == sign(l[i].w) && abs(depth - l[i].w) < kTolerance) {
      lMin = min(lMin, l[i].xyz);
      lMax = max(lMax, l[i].xyz);
      tMin = min(tMin, t[i].xyz);
      tMax = max(tMax, t[i].xyz);
      anySuccess = true;
    }
  }

  if (anySuccess) {
    clampedLighting = max(lMin, min(lighting, lMax));
    clampedTransmittance = max(tMin, min(transmittance, tMax));
  } else {
    clampedLighting = lighting;
    clampedTransmittance = transmittance;
  }
}

[numthreads(8, 8, 1)]
void REPROJECT(uint3 id : SV_DispatchThreadID) {
  UniversalCloudLayerRenderSettings layerSettings = _ExpanseCloudLayers[_layerIndex];

  /* First, render the G-Buffer. */
  float3 d = -GetSkyViewDirWS((id.xy + 0.5) / _subresolution.xy);
  float3 view = -GetSkyViewDirWS((_framebufferResolution.xy * 0.5 + 0.5) / _subresolution.xy);
  _GBuffer[uint3(id.xy, _layerIndex)] = float4(RenderGBuffer(d, layerSettings), 0, 0);

  /* If density is zero, write a null result. */
  if (layerSettings.density == 0) {
    _LightingFramebuffers[uint3(id.xy, _layerIndex)] = float4(0, 0, 0, -1);
    _TransmittanceHitFramebuffers[uint3(id.xy, _layerIndex)] = float4(1, 1, 1, -1);
    return;
  }

  if (layerSettings.reprojectionFrames > 1) {
    uint updatedSubpixelID = Clouds::getCurrentSubpixelID(_frameCount, layerSettings.reprojectionFrames);
    uint subpixelID = Clouds::getSubpixelID(id.xy, layerSettings.reprojectionFrames);
    if (subpixelID != updatedSubpixelID) {

      /* This pixel is stale---it wasn't updated this frame. Our job is to
      * figure out what pixel we can use nearby that is close enough to
      * being the correct pixel for this frame.
      *
      * The best way to do this is to get some estimate of where the
      * content of a pixel is in worldspace in this frame. We can then use the
      * last camera matrix to figure out where it was in the previous frame,
      * and then grab the lighting and transmittance info from there. */


      /* It's safe for us to directly load from the framebuffer we're writing
      * to because we know we will never be writing to the pixel we are
      * updating in this thread from another thread. */
      uint2 lowResID = clamp((round(id.xy / layerSettings.reprojectionFrames) * layerSettings.reprojectionFrames) + Clouds::getCurrentSubpixel(_frameCount, layerSettings.reprojectionFrames), 0, _framebufferResolution.xy-1);
      float4 tAndTransmittanceEstimate = _TransmittanceHitFramebuffers[uint3(lowResID, _layerIndex)];
      float tEstimate = tAndTransmittanceEstimate.w;
      float depthEstimate = Geometry::sampleCameraDistance((id.xy + 0.5) / _framebufferResolution.xy, d, view);
      // Just use depth estimate if we hit geo.
      if (depthEstimate > 0) {
        tEstimate = depthEstimate;
      }

      // TODO: investigate using these for reprojection on clouds over geo somehow?

      /* We can only reliably reproject if we have a valid t estimate---that is,
      * if we hit the cloud volume. Otherwise, we have no cloud render
      * at this pixel at all. */
      bool reprojectSuccessful = false;
      if (tEstimate > 0) {
        /* Use the t estimate to get the position in worldspace. */
        float2 reprojectedUV = 0;
        if (depthEstimate < 0) {
          float3 wsPosition = _WorldSpaceCameraPos1.xyz + d * tEstimate;
          /* Transform it to clip space using the previous camera transformation. */
          float3 prevCameraSpace = mul(_previousViewMatrix, float4(wsPosition, 1)).xyz;
          float4 prevClipSpace = mul(_previousProjectionMatrix, float4(prevCameraSpace, 1));
          float2 prevNDC = prevClipSpace.xy / prevClipSpace.w;
          reprojectedUV = (prevNDC + 1) / 2;
        } else {
          float3 wsPosition = _WorldSpaceCameraPos1.xyz + d * tEstimate;
          /* Transform it to clip space using the previous camera transformation. */
          float2 motionVector;
          DecodeMotionVector(LOAD_TEXTURE2D_X(_CameraMotionVectorsTexture_Copy, uint2(id.xy/_subresolution.xy)), motionVector);
          reprojectedUV = ((id.xy + 0.5) / (_framebufferResolution.xy)) - motionVector;
        }
        /* Finally, check if we're in bounds of the framebuffer. */
        float2 tolerance = layerSettings.reprojectionFrames/_framebufferResolution.xy;
        if (Utilities::boundsCheckNoEpsilon(reprojectedUV.x, float2(0, 1 - tolerance.x)) && Utilities::boundsCheckNoEpsilon(reprojectedUV.y, float2(0, 1 - tolerance.y))) {
          float4 prevLighting = SAMPLE_TEXTURE2D_ARRAY_LOD(_PrevLightingFramebuffers, s_linear_clamp_sampler, reprojectedUV, _layerIndex, 0);
          float4 prevTransmittance = SAMPLE_TEXTURE2D_ARRAY_LOD(_PrevTransmittanceHitFramebuffers, s_linear_clamp_sampler, reprojectedUV, _layerIndex, 0);
          float3 clampedLighting = prevLighting.xyz;
          float3 clampedTransmittance = prevTransmittance.xyz;
          neighborhoodClampWithDepthRejection(_layerIndex, layerSettings.reprojectionFrames, prevTransmittance.xyz, 
            prevLighting.xyz, lowResID, depthEstimate, clampedTransmittance, clampedLighting);
          _LightingFramebuffers[uint3(id.xy, _layerIndex)] = float4(clampedLighting, prevLighting.w);
          _TransmittanceHitFramebuffers[uint3(id.xy, _layerIndex)] = float4(clampedTransmittance, prevTransmittance.w);
          reprojectSuccessful = true;
        }
      }

      /* If we were unable to reproject successfully, use the most recently
      * updated pixel we are closest to. */
      if (!reprojectSuccessful) {
        _LightingFramebuffers[uint3(id.xy, _layerIndex)] = _LightingFramebuffers[uint3(lowResID, _layerIndex)];
        _TransmittanceHitFramebuffers[uint3(id.xy, _layerIndex)] = _TransmittanceHitFramebuffers[uint3(lowResID, _layerIndex)];
      }
    }
  }

  /* We can use a similar strategy for TAA. */
  if (layerSettings.useTemporalDenoising) {
    float4 tAndTransmittanceEstimate = _TransmittanceHitFramebuffers[uint3(id.xy, _layerIndex)];
    float tEstimate = tAndTransmittanceEstimate.w;
    float depthEstimate = Geometry::sampleCameraDistance((id.xy + 0.5) / _framebufferResolution.xy, d, view);
    // Just use depth estimate if we hit geo.
    if (depthEstimate > 0) {
      tEstimate = depthEstimate;
    }

    /* We can only reliably reproject if we have a valid t estimate---that is,
     * if we hit the cloud volume. Otherwise, we have no cloud render
     * at this pixel at all. */
    if (tEstimate > 0) {
      float2 reprojectedUV = 0;
      if (depthEstimate < 0) {
        /* Use the t estimate to get the position in worldspace. */
        float3 wsPosition = _WorldSpaceCameraPos1.xyz + d * tEstimate;
        /* Transform it to clip space using the previous camera transformation. */
        float3 prevCameraSpace = mul(_previousViewMatrix, float4(wsPosition, 1)).xyz;
        float4 prevClipSpace = mul(_previousProjectionMatrix, float4(prevCameraSpace, 1));
        float2 prevNDC = prevClipSpace.xy / prevClipSpace.w;
        reprojectedUV = (prevNDC + 1) / 2;
      } else {
        float2 motionVector;
        DecodeMotionVector(LOAD_TEXTURE2D_X(_CameraMotionVectorsTexture_Copy, uint2(id.xy / _subresolution.xy)), motionVector);
        reprojectedUV = ((id.xy + 0.5) / (_framebufferResolution.xy)) - motionVector;
      }
      /* Finally, check if we're in bounds of the framebuffer. */
      float2 tolerance = layerSettings.reprojectionFrames/_framebufferResolution.xy;
      if (Utilities::boundsCheckNoEpsilon(reprojectedUV.x, float2(0, 1 - tolerance.x)) && Utilities::boundsCheckNoEpsilon(reprojectedUV.y, float2(0, 1 - tolerance.y))) {
        float3 prevLighting = SAMPLE_TEXTURE2D_ARRAY_LOD(_PrevLightingFramebuffers, s_linear_clamp_sampler, reprojectedUV, _layerIndex, 0).xyz;
        float3 prevTransmittance = SAMPLE_TEXTURE2D_ARRAY_LOD(_PrevTransmittanceHitFramebuffers, s_linear_clamp_sampler, reprojectedUV, _layerIndex, 0).xyz;
        float3 clampedLighting = prevLighting;
        float3 clampedTransmittance = prevTransmittance;
        neighborhoodClamp(_layerIndex, 1, prevTransmittance.xyz, 
          prevLighting.xyz, id.xy, clampedTransmittance, clampedLighting);
        _LightingFramebuffers[uint3(id.xy, _layerIndex)] = float4(layerSettings.temporalDenoisingRatio * _LightingFramebuffers[uint3(id.xy, _layerIndex)].xyz + (1-layerSettings.temporalDenoisingRatio) * clampedLighting, _LightingFramebuffers[uint3(id.xy, _layerIndex)].w);
        _TransmittanceHitFramebuffers[uint3(id.xy, _layerIndex)] = float4(layerSettings.temporalDenoisingRatio * tAndTransmittanceEstimate.xyz + (1-layerSettings.temporalDenoisingRatio) * clampedTransmittance, tAndTransmittanceEstimate.w);
      }
    }
  }
}

[numthreads(8, 8, 1)]
void SHADOWMAP(uint3 id : SV_DispatchThreadID) {
  UniversalCloudLayerRenderSettings layerSettings = _ExpanseCloudLayers[_layerIndex];
  PlanetRenderSettings planet = _ExpansePlanetRenderSettings[0];
  QualityRenderSettings quality = _ExpanseQualitySettings[0];
  DirectionalLightRenderSettings shadowmapLight = _ExpanseCloudShadowDirectionalLights[_shadowLightIndex];

  uint2 pixel = id.xy;

  /* Layers with zero density have full transmittance. */
  if (layerSettings.density == 0) {
    _ShadowMapFramebuffers[uint3(pixel, _shadowLayerIndex)] = float4(1, 1, 1, -1);
    return;
  }

  float3 L = normalize(shadowmapLight.direction.xyz);
  float3 lightRight = normalize(cross(L, float3(0, 1, 0)));
  float3 lightUp = normalize(cross(lightRight, L));
  float2 normalizedDevice = 2 * ((pixel + 0.5) / _shadowMapResolution.xy) - 1;
  /* Our TNB frame may have the wrong winding order. To fix this we pass 
   * in a sign flip for the NDC coordinates that's based off the 
   * x euler angle of the light. */
  normalizedDevice *= shadowmapLight.shadowmapNDCSign;
  /* Just put the film plane really far away. It doesn't matter where it is
   * since the projection is orthographic---we just need to make sure it's
   * far enough away that it is always outside the cloud volume/planes. */
  const float filmPlaneDistance = 10000000;
  float3 worldspaceFilmPlaneCoordinate = L * filmPlaneDistance + (quality.cloudShadowMapFilmPlaneScale * lightRight * normalizedDevice.x) + (quality.cloudShadowMapFilmPlaneScale * lightUp * normalizedDevice.y);
  float3 o = Mapping::transformPointToPlanetSpace(worldspaceFilmPlaneCoordinate, planet.originOffset, planet.radius);
  float3 d = -L;

  // HACK: use a big depth value cause we just want to render to the intersection.
  float depth = 20000000;

  /* Create the right kind of geometry and render! */
  CloudResult result;
  switch (layerSettings.geometryType) {
    case CLOUDGEOMETRYTYPE_PLANE: {
      CloudPlane geometry = CloudPlane::CreateCloudPlane(layerSettings.geometryXExtent,
        layerSettings.geometryZExtent, layerSettings.geometryHeight, layerSettings.apparentThickness, planet.radius);
      result = Clouds::renderCloudsShadowMap2D(layerSettings, geometry, o, d);
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_PLANE: {
      CloudCurvedPlane geometry = CloudCurvedPlane::CreateCloudCurvedPlane(layerSettings.geometryXExtent,
        layerSettings.geometryZExtent, layerSettings.geometryHeight, layerSettings.apparentThickness, planet.radius);
      result = Clouds::renderCloudsShadowMap2D(layerSettings, geometry, o, d);
      break;
    }
    case CLOUDGEOMETRYTYPE_BOX_VOLUME: {
      CloudBoxVolume geometry = CloudBoxVolume::CreateCloudBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      result = Clouds::renderCloudsShadowMap3D(layerSettings, geometry, o, d, depth);
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_BOX_VOLUME: {
      CloudCurvedBoxVolume geometry = CloudCurvedBoxVolume::CreateCloudCurvedBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      result = Clouds::renderCloudsShadowMap3D(layerSettings, geometry, o, d, depth);
      break;
    }
    default: {
      result.lighting = 0;
      result.transmittance = 1;
      result.t = -1;
      result.geoHit = -1;
      break;
    }
  }

  /* Transmittance is limited by an artistic override. */
  result.transmittance = max(result.transmittance, 1 - layerSettings.maxShadowIntensity);
  _ShadowMapFramebuffers[uint3(pixel, _shadowLayerIndex)] = float4(result.transmittance, result.t);
}

[numthreads(8, 8, 1)]
void REFLECTION(uint3 id : SV_DispatchThreadID) {
  UniversalCloudLayerRenderSettings layerSettings = _ExpanseCloudLayers[_layerIndex];
  PlanetRenderSettings planet = _ExpansePlanetRenderSettings[0];

  uint2 subPixel = Clouds::getCurrentSubpixel(_frameCount, _reflectionProbeReprojectionFrames);
  uint2 pixel = id.xy * _reflectionProbeReprojectionFrames + subPixel;

  float2 uv = (pixel.xy + 0.5) / _reflectionProbeResolution.xy;

  /* Convert to direction by unmapping polar coordinate. */
  float3 d = Mapping::unmapPolar(uv);
  
  /* Convert camera origin to planet space. */
  float3 o = Mapping::transformPointToPlanetSpace(_WorldSpaceCameraPos1.xyz,
    planet.originOffset, planet.radius);

  /* Set depth to be -1, so we just render the entire cloud volume. */
  float depth = -1;

  /* Sample ambient light probe. */
  const int kAmbientLightSamples = 5;
  float3 ambient = 0;
  for (int i = 0; i < kAmbientLightSamples; i++) {
    float3 fibonacciDir = Utilities::fibonacciHemisphere(i, kAmbientLightSamples);
    float muFibonacci = dot(normalize(o), fibonacciDir);
    SkyIntersectionData intersectionFibonacci = AtmosphereGeometry::traceSkyVolume(o, fibonacciDir,
      planet.radius, planet.atmosphereRadius);
    float tFibonacci = intersectionFibonacci.endT - intersectionFibonacci.startT;
    float theta = AtmosphereMapping::d_to_theta(fibonacciDir, o);
    float2 atmoUV = AtmosphereMapping::mapSkyRenderCoordinate(length(o), muFibonacci,
      theta, planet.atmosphereRadius, planet.radius, tFibonacci,
      intersectionFibonacci.groundHit, 64, 64); // HACK: 64's here are a guess at the sky texture res... but it doesn't matter since we're taking such a low frequency estimate.
    float4 atmosphere = SAMPLE_TEXTURE2D_LOD(_SkyViewTex, s_linear_clamp_sampler, atmoUV, 0);
    // [HACK]: to avoid the sky ambient contribution getting too blue, desaturate it!
    const float3 desaturate = 0.5;
    float3 grayscale = Utilities::average(atmosphere.xyz);
    ambient += lerp(atmosphere.xyz, grayscale, desaturate);
  }
  ambient /= float(kAmbientLightSamples);

  /* HACK: use a super low sample count to speed things up. */
  layerSettings.coarseStepRange = float2(3, 6);
  layerSettings.detailStepRange = float2(6, 12);

  /* Create the right kind of geometry and render! */
  CloudResult result;
  switch (layerSettings.geometryType) {
    case CLOUDGEOMETRYTYPE_PLANE: {
      CloudPlane geometry = CloudPlane::CreateCloudPlane(layerSettings.geometryXExtent,
        layerSettings.geometryZExtent, layerSettings.geometryHeight, layerSettings.apparentThickness, planet.radius);
      result = Clouds::renderClouds2D(layerSettings, geometry, o, d, ambient);
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_PLANE: {
      CloudCurvedPlane geometry = CloudCurvedPlane::CreateCloudCurvedPlane(layerSettings.geometryXExtent,
        layerSettings.geometryZExtent, layerSettings.geometryHeight, layerSettings.apparentThickness, planet.radius);
      result = Clouds::renderClouds2D(layerSettings, geometry, o, d, ambient);
      break;
    }
    case CLOUDGEOMETRYTYPE_BOX_VOLUME: {
      float blueNoise = Random::random_3_1(float3(uv, (uint(_frameCount) % 256) / 256.0));
      CloudBoxVolume geometry = CloudBoxVolume::CreateCloudBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      result = Clouds::renderClouds3D(layerSettings, geometry, o, d, depth, blueNoise, ambient, _frameCount);
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_BOX_VOLUME: {
      float blueNoise = Random::random_3_1(float3(uv, (uint(_frameCount) % 256) / 256.0));
      CloudCurvedBoxVolume geometry = CloudCurvedBoxVolume::CreateCloudCurvedBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      result = Clouds::renderClouds3D(layerSettings, geometry, o, d, depth, blueNoise, ambient, _frameCount);
      break;
    }
    default: {
      result.lighting = 0;
      result.transmittance = 1;
      result.t = -1;
      result.geoHit = -1;
      break;
    }
  }

  /* Temporally accumulate over 8 frames. */
  const float kAccumulationRatio = rcp((float) _reflectionProbeDenoisingFrames);
  _LightingFramebuffers[uint3(pixel.xy, _layerIndex)] = lerp(_LightingFramebuffers[uint3(pixel.xy, _layerIndex)], float4(result.lighting, Utilities::average(result.transmittance)), kAccumulationRatio);
  _ReflectionT[uint3(pixel.xy, _layerIndex)] = result.t;
}

[numthreads(8, 1, 1)]
void GAMEPLAY(uint3 id : SV_DispatchThreadID) {
  /* Skip queries we can't write into. */
  if (id.x >= uint(_numGameplayQueries)) {
    return;
  }

  UniversalCloudLayerRenderSettings layerSettings = _ExpanseCloudLayers[_layerIndex];
  PlanetRenderSettings planet = _ExpansePlanetRenderSettings[0];
  
  QueryInfo q = _GameplayQueryBuffer[id.x];
  
  /* Queries on layers with zero density have no affect on the result. */
  if (layerSettings.density == 0) {
    return;
  }

  /* Some geometric info about the query. */
  float3 start = Mapping::transformPointToPlanetSpace(q.startWS, planet.originOffset, planet.radius);
  float3 end = Mapping::transformPointToPlanetSpace(q.endWS, planet.originOffset, planet.radius);
  float3 d = normalize(end - start);
  float distance = length(end - start);


  CloudResult visibilityResult;
  switch (layerSettings.geometryType) {
    case CLOUDGEOMETRYTYPE_BOX_VOLUME: {
      CloudBoxVolume geometry = CloudBoxVolume::CreateCloudBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      visibilityResult = Clouds::renderCloudsShadowMap3D(layerSettings, geometry, start, d, distance);
      q.density += layerSettings.density * Clouds::takeMediaSample3DHighLOD(layerSettings, start, geometry).x;
      q.visibility *= Utilities::average(visibilityResult.transmittance);
      break;
    }
    case CLOUDGEOMETRYTYPE_CURVED_BOX_VOLUME: {
      CloudCurvedBoxVolume geometry = CloudCurvedBoxVolume::CreateCloudCurvedBoxVolume(layerSettings.geometryXExtent,
        layerSettings.geometryYExtent, layerSettings.geometryZExtent, planet.radius);
      visibilityResult = Clouds::renderCloudsShadowMap3D(layerSettings, geometry, start, d, distance);
      q.density += layerSettings.density * Clouds::takeMediaSample3DHighLOD(layerSettings, start, geometry).x;
      q.visibility *= Utilities::average(visibilityResult.transmittance);
      break;
    }
    default: {
      q.density = 0;
      q.visibility = 1;
      return;
    }
  }

  /* Write back query info. */
  _GameplayQueryBuffer[id.x] = q;
}